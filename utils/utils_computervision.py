from ultralytics import YOLO
import cv2
import supervision as sv
import torch
import os

# Detectar autom√°ticamente si hay GPU disponible
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"üîß Dispositivo detectado: {device}")

# Bandera para saber si estamos usando TensorRT o PyTorch
USANDO_TENSORRT = False

# Intentar cargar modelo TensorRT primero (m√°s r√°pido); si no existe, usar PyTorch (.pt)
# NOTA: ajusta el nombre del archivo .engine al que realmente tienes en la carpeta modelos
engine_path = "modelos/yolo26n.engine"  # tu modelo TensorRT
pt_path = "modelos/yolov8n.pt"          # modelo PyTorch de respaldo

if os.path.exists(engine_path):
    print("üöÄ Cargando modelo TensorRT (optimizado para Jetson)...")
    try:
        modelo = YOLO(engine_path)
        USANDO_TENSORRT = True
        print("‚úÖ Modelo TensorRT cargado")
    except Exception as e:
        print(f"‚ùå No se pudo cargar TensorRT: {e}")
        print("üì¶ Recurriendo a modelo PyTorch (.pt)...")
        modelo = YOLO(pt_path)
        USANDO_TENSORRT = False
        if device == 'cuda':
            modelo.to(device)
            print("‚úÖ Modelo PyTorch cargado en GPU")
        else:
            print("‚ö†Ô∏è  GPU no disponible, usando CPU")
else:
    print("üì¶ Cargando modelo PyTorch (.pt)...")
    modelo = YOLO(pt_path)
    USANDO_TENSORRT = False
    # Mover el modelo a GPU si est√° disponible (solo v√°lido para modelos PyTorch)
    if device == 'cuda':
        modelo.to(device)
        print("‚úÖ Modelo PyTorch cargado en GPU")
    else:
        print("‚ö†Ô∏è  GPU no disponible, usando CPU")

tracker = sv.ByteTrack()
box_annotator= sv.BoxAnnotator()
label_annotator= sv.LabelAnnotator()

def detectar_objetos(frame, modelo= modelo):
    # Optimizaci√≥n: Reducir tama√±o de imagen para YOLO (m√°s r√°pido)
    # Guardar tama√±o original para escalar detecciones despu√©s
    altura_original, ancho_original = frame.shape[:2]
    
    # Optimizaci√≥n agresiva: Reducir a m√°ximo 480px para procesamiento m√°s r√°pido
    # Con 4 c√°maras, necesitamos procesar m√°s r√°pido
    TAMANO_PROCESAMIENTO = 480
    escala = min(TAMANO_PROCESAMIENTO / ancho_original, TAMANO_PROCESAMIENTO / altura_original)
    if escala < 1.0:
        nuevo_ancho = int(ancho_original * escala)
        nueva_altura = int(altura_original * escala)
        frame_peque√±o = cv2.resize(frame, (nuevo_ancho, nueva_altura), interpolation=cv2.INTER_LINEAR)
    else:
        frame_peque√±o = frame
        escala = 1.0
    
    # CR√çTICO: Asegurar que el modelo y los datos est√©n en GPU
    # Ultralytics puede hacer transferencias innecesarias CPU-GPU
    # Especificar device expl√≠citamente y forzar GPU
    resultados= modelo.predict(
        frame_peque√±o, 
        conf=0.50, 
        device=device,  # Asegurar que use GPU
        imgsz=480,  # Reducido de 640 a 480 para m√°s velocidad
        verbose=False,  # Desactivar logs para mejor rendimiento
        half=False,  # No usar FP16 en Jetson (puede ser m√°s lento)
        agnostic_nms=False,  # NMS normal (m√°s r√°pido que agnostic)
        stream=False  # Procesar de forma s√≠ncrona (m√°s eficiente para Jetson)
    )[0]
    
    detections = sv.Detections.from_ultralytics(resultados)
    
    # Escalar detecciones de vuelta al tama√±o original si se redujo
    if escala < 1.0:
        detections.xyxy = detections.xyxy / escala
        # Tambi√©n escalar los puntos centrales si existen
        if hasattr(detections, 'xyxy') and len(detections.xyxy) > 0:
            # Las coordenadas ya est√°n escaladas correctamente con xyxy
            pass
    
    detections = tracker.update_with_detections(detections)
    
    labels = [
        f"#{tracker_id} {class_name}"
        for class_name, tracker_id
        in zip(detections.data["class_name"], detections.tracker_id)
    ]
    
    annotated_frame = box_annotator.annotate(
        scene=frame.copy(), detections=detections)
    annotated_frame = label_annotator.annotate(
        scene=annotated_frame, detections=detections, labels=labels)
    return annotated_frame

def detect(frame, modelo= modelo):
    resultados= modelo.predict(frame, conf=0.5, device=device)[0]
    detections= resultados.plot()
    return detections

def linea_deteccion(frame, punto_inicio:tuple[int, int], punto_fin:tuple[int, int]):
    linea= cv2.line(frame, punto_inicio, punto_fin, (0, 0, 255), 2)
    return linea
